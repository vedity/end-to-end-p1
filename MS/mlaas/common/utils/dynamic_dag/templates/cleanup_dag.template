
#* Relative Imports
from preprocess.utils.preprocessing import PreprocessingClass
from database import *

#* Library Imports
from datetime import datetime, timedelta
import sys

#* Airflow Imports
from airflow import DAG
import airflow
from airflow.operators.dummy_operator import DummyOperator
from airflow.operators.python_operator import PythonOperator

#* Defining Objects
PC_OBJ = PreprocessingClass(database,user,password,host,port)

yesterday_date = datetime.strftime(datetime.now() - timedelta(1), '%Y-%m-%d')

main_dag_id = #DAG_ID

args = {
    'owner': 'airflow',
    'start_date': airflow.utils.dates.days_ago(1),      
    'provide_context': True, 
}

dag = DAG(
    main_dag_id,
    default_args=args,    
    description='A Dynamically Generated DAG.',
    catchup=False,
    schedule_interval = '@once',                         
)

#? Getting Required Parameters

master_dict = #MASTER_DICT 

if int(master_dict['active']) == 0:
    sys.exit()

else:
    operation = master_dict['operation_dict']
    value_dict = master_dict['values_dict']
    schema_id = int(master_dict['schema_id'])
    dataset_id = int(master_dict['dataset_id'])
    project_id = int(master_dict['project_id'])
    save_as = master_dict['save_as']
    visibility = master_dict['visibility']
    dataset_name = master_dict['dataset_name']
    dataset_desc = master_dict['dataset_desc']
    new_user_name = master_dict['user_name']

#Note: This thing might be causing the connection issues
DBObject,connection,connection_string = PC_OBJ.get_db_connection()
if connection == None :
    raise DatabaseConnectionFailed(500)

#Get the dataframe of dataset detail based on the dataset id
dataframe = DBObject.get_dataset_detail(DBObject,connection,dataset_id)

#Extract the dataframe based on its column name as key
table_name,dataset_visibility,user_name = str(dataframe['dataset_table_name'][0]),str(dataframe['dataset_visibility'][0]),str(dataframe['user_name'][0])

if dataset_visibility == 'private':
    dataset_table_name = user_name+'."'+table_name+'"'
else:
    dataset_table_name = 'public'+'."'+table_name+'"'

#get the Column list
column_list = PC_OBJ.get_col_names(DBObject, connection ,schema_id)
old_column_list = PC_OBJ.get_col_names(DBObject, connection ,schema_id,json = False,original = True)

schema_column_list = DBObject.get_schema_column(connection,schema_id)

op_dict = {
    1 : PC_OBJ.discard_missing_values,
    11 : PC_OBJ.discard_noise,
    21 : PC_OBJ.delete_above,
    31 : PC_OBJ.delete_below,
    41 : PC_OBJ.remove_noise,
    51 : PC_OBJ.mean_imputation,
    61 : PC_OBJ.median_imputation,
    71 : PC_OBJ.mode_imputation,
    81 : PC_OBJ.missing_category_imputation,
    91 : PC_OBJ.end_of_distribution,
    101 : PC_OBJ.frequent_category_imputation,
    111 : PC_OBJ.missing_category_imputation,
    121 : PC_OBJ.random_sample_imputation,
    131 : PC_OBJ.repl_noise_mean,
    141 : PC_OBJ.repl_noise_median,
    151 : PC_OBJ.repl_noise_mode,
    161 : PC_OBJ.repl_noise_eod,
    171 : PC_OBJ.repl_noise_random_sample,
    181 : PC_OBJ.repl_noise_arbitrary_val,
    191 : PC_OBJ.rem_outliers_ext_val_analysis,
    201 : PC_OBJ.rem_outliers_z_score,
    202 : PC_OBJ.rem_outliers_lof,
    211 : PC_OBJ.repl_outliers_mean_ext_val_analysis,
    221 : PC_OBJ.repl_outliers_mean_z_score,
    231 : PC_OBJ.repl_outliers_med_ext_val_analysis,
    241 : PC_OBJ.repl_outliers_med_z_score,
    242 : PC_OBJ.repl_outliers_mean_lof,
    243 : PC_OBJ.repl_outliers_median_lof,
    251 : PC_OBJ.apply_log_transformation,
    261 : PC_OBJ.label_encoding,
    271 : PC_OBJ.one_hot_encoding,
    281 : PC_OBJ.add_to_column,
    291 : PC_OBJ.subtract_from_column,
    301 : PC_OBJ.divide_column,
    311 : PC_OBJ.multiply_column,
    321 : PC_OBJ.split_date_column
}

def dag_end(DBObject,connection,dataset_id,project_id,dag_id,new_user_name,dataset_name,col_list,**kwargs):
    '''
        To reset the dag status
    '''
    status = PC_OBJ.check_failed_col(DBObject, connection,dataset_id,project_id,new_user_name,col_list, dag_id)
    activity_id = 'cl_2'
    status = PC_OBJ.get_cleanup_startend_desc(DBObject,connection,dataset_id,project_id,activity_id,new_user_name,dataset_name,flag=False)
    return status

#? Making Dynamic Tasks
t1= DummyOperator(task_id='start',dag=dag)
t2= PythonOperator(
            task_id='Finishing_Up',
            dag=dag,
            provide_context=True,
            python_callable=PC_OBJ.update_schema_flag_status,
            op_args=[DBObject,connection,schema_id,dataset_id,schema_column_list],
            trigger_rule="all_done")
t4= PythonOperator(
            task_id='Enable_Cleanup_Page',
            dag=dag,
            provide_context=True,
            python_callable=dag_end,
            op_args=[DBObject,connection,dataset_id,project_id,main_dag_id,new_user_name,dataset_name,column_list],
            trigger_rule="all_done")

if save_as == 'True':
    t3 = PythonOperator(
                task_id='Save-As',
                dag=dag,
                provide_context=True,
                python_callable=PC_OBJ.SaveAs,
                op_args=[DBObject,connection,project_id,schema_id,table_name,user_name,dataset_visibility,dataset_name,visibility,dataset_desc],
                trigger_rule="all_done")
    t2.set_downstream(t3)
    t3.set_downstream(t4)
else:
    t2.set_downstream(t4)


previous_task = t1
i = 0
daglist = []    

for index in operation.keys():
    dynamicTaskOne = DummyOperator(
    task_id='Function_' +str(index) + '_Start',
    dag=dag,)

    for task in daglist:
        task.set_downstream(dynamicTaskOne)

    previous_task.set_downstream(dynamicTaskOne)
    daglist = []    

    value = value_dict[index]
    for j,col in enumerate(operation[index]): 
        
        #? Which parameters should be given to which function
        param_dict = {
            1 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            11 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            21 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            31 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            41 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            51 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            61 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            71 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            81 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j], True],
            91 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            101 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            111 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            121 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            131 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            141 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            151 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            161 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            171 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            181 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            191 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            201 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            202 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            211 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            221 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            231 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            241 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            242 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            243 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            251 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            261 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]],
            271 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], schema_id],
            281 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            291 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            301 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            311 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col], value[j]],
            321 : [DBObject,connection,project_id,column_list,old_column_list, dataset_table_name, [col]]
        }
        
        dynamicTask = PythonOperator(
            task_id='Operation_' + str(index) + "_col_" + str(col),
            dag=dag,
            provide_context=True,
            python_callable=op_dict[index],
            op_args=param_dict[index])

        dynamicTaskOne.set_downstream(dynamicTask)
        daglist.append(dynamicTask)
        previous_task = dynamicTaskOne

    i+=1
    if i == len(operation.keys()):
        previous_task.set_downstream(t2)
        for task in daglist:
            task.set_downstream(t2)
